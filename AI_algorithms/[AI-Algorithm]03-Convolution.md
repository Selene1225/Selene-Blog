# [AI-Algorithm] 03-Convolution

## 1. 为什么用卷积？

想象你要处理一张很普通的手机照片：1000×1000 像素，RGB 3通道。

输入向量的大小是：1000×1000×3=3,000,000 (三百万维)。

如果你用全连接层（Dense Layer），假设只有 1000 个神经元：

> 权重数量 = 3,000,000×1,000=30 亿个参数！

这不仅显存瞬间爆炸，而且根本训练不出来（过拟合风险极高）。


再考虑如果你在图片的左上角学会了识别“猫”，全连接层换到图片的右下角看到猫时，它完全不认识。因为它把每个像素的位置都“写死”了，它认为“左上角的像素”和“右下角的像素”是完全两回事。

人类的直觉： 猫就是猫，不管它在画面的哪里。

为了解决这些问题，就用到了卷积！

卷积的核心思想是：“拿着手电筒（Filter）在图片上滑动”。
1. 局部连接 (Local Connectivity)： 我们不需要看整张图，每次只看一个 3×3 的小窗口。
2. 权值共享 (Weight Sharing)： 这是核心！ 我们用同一个 3×3 的过滤器（Filter），扫描整张大图。
  - 物理含义： 如果这个过滤器是用来检测“垂直边缘”的，那么不管边缘在图片哪里，我都能检测出来。
  - 参数量对比： 同样处理上面的图，一个 3×3 的卷积核，参数只有 9个！从 30亿 降到 9，这就是卷积的威力。

核心公式
> 假设输入图是 $X$，卷积核是 $K$（大小 $k×k$），输出是 $Y$。 在位置 $(i,j)$ 的输出值是：

$Y_{i,j} = \sum_{m=0}^{k−1} \sum_{n=0}^{k−1}X_{i+m,j+n} \cdot K_{m,n}+b$
直觉翻译： 对应位置相乘，然后求和。就像把两张透明纸叠在一起看重合度。

## 3. 面试官问题

**1. 计算一个卷机层的参数量，假设输入是 $28 \times 28 \times 128$ ，使用 $3 \times 3$ 的卷积核，输出通道是256，如果使用同等维度的全连接层，参数量会差多少？**

回答模板：

1. 卷积层参数计算：卷积核的参数只与核大小核输入/输出通道数有关，与图片长宽(28*28)无关，所以公式：$(K \times K \times C_{in} + 1_{bias}) \times C_{out}$ 计算：$(3 \times 3 \times 128 + 1) \times 256 \approx 294912$（大约30w参数）

2. 全连接层参数计算：全连接层需要把输入Flatten，输入维度：$28 \times 28 \times 128 \approx 100000$, 输出维度（为了保持信息量同级）：$28 \times 28 \times 256 \approx 200000$。权重矩阵：$10^5 \times 2 \cdot 10^5 = 2 \cdot 10^{10}$（200亿参数）

3. 全连接层的参数量是卷积层近10万倍，所以卷积就是利用图像的局部性核平移不变性来实现权值共享。